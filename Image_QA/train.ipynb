{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC2T0KlinNPQ"
      },
      "source": [
        "### Img, question, cross_attn_out are concatenated together\n",
        "### Two norms\n",
        "### Use Large_vocab_Epoch0002 weights\n",
        "### vocab size 5500, stored in token_vocab\n",
        "### whole model saved in VQA_final_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IBooPi5leGj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import collections\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from PIL import Image\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preparing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTaVjVijNv8T",
        "outputId": "aa3d13cb-3435-49a3-c82f-0827826999a3"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !unzip drive/MyDrive/data.zip -d /content/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBthRcCZP0lg",
        "outputId": "e6b981d5-d8d9-49a0-c856-88eef449bf0a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k46uxkj5leGk"
      },
      "outputs": [],
      "source": [
        "question_file = \"/content/drive/MyDrive/v2_OpenEnded_mscoco_train2014_questions.json\"\n",
        "question_file_val = \"/content/drive/MyDrive/v2_OpenEnded_mscoco_val2014_questions.json\"\n",
        "IMG_PATH  = \"/content/data/train2014/train2014/\"\n",
        "\n",
        "with open(question_file, \"r\") as f:\n",
        "    question = json.load(f)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "question_image_pair = collections.defaultdict(list)\n",
        "for item in question['questions']:\n",
        "    question = item['question']\n",
        "    tokens = word_tokenize(question)\n",
        "    tokens = [t.lower() for t in tokens if t not in '''!,.;?()-[]{};:'\"\\<>/@#$+%^&*_~''']\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    question = \" \".join(tokens)\n",
        "    # image_path = IMG_PATH + 'COCO_train2014_' + '%012d.jpg' % (item['image_id'])\n",
        "    image_path = IMG_PATH + 'COCO_train2014_' + '%012d.jpg' % (item['image_id'])\n",
        "    question_image_pair[image_path].append(question)\n",
        "\n",
        "with open(question_file_val, \"r\") as f:\n",
        "    question = json.load(f)\n",
        "IMG_PATH_VAL  = \"/content/data/val2014/val2014/\"\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "question_image_pair_val = collections.defaultdict(list)\n",
        "for item in question['questions']:\n",
        "    question = item['question']\n",
        "    tokens = word_tokenize(question)\n",
        "    tokens = [t.lower() for t in tokens if t not in '''!,.;?()-[]{};:'\"\\<>/@#$+%^&*_~''']\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    question = \" \".join(tokens)\n",
        "    # image_path = IMG_PATH + 'COCO_train2014_' + '%012d.jpg' % (item['image_id'])\n",
        "    image_path = IMG_PATH_VAL + 'COCO_val2014_' + '%012d.jpg' % (item['image_id'])\n",
        "    question_image_pair_val[image_path].append(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-di7tWJOleGl"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "answer_file = \"/content/drive/MyDrive/v2_mscoco_train2014_annotations.json\"\n",
        "with open(answer_file, \"r\") as f:\n",
        "    answer = json.load(f)\n",
        "    \n",
        "answer_image_pair = collections.defaultdict(list)\n",
        "for item in answer['annotations']:\n",
        "    ri = random.randint(0, 9)\n",
        "    answer = f\"{item['answers'][ri]['answer']}\"\n",
        "    tokens = word_tokenize(answer)\n",
        "    tokens = [t.lower() for t in tokens if t not in '''!,.;?()-[]{};:'\"\\<>/@#$+%^&*_~''']\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    answer = \" \".join(tokens)\n",
        "    # image_path = IMG_PATH + 'COCO_train2014_' + '%012d.jpg' % (item['image_id'])\n",
        "    image_path = IMG_PATH + 'COCO_train2014_' + '%012d.jpg' % (item['image_id'])\n",
        "    answer_image_pair[image_path].append(answer)\n",
        "    \n",
        "answer_file_val = \"/content/drive/MyDrive/v2_mscoco_val2014_annotations.json\"\n",
        "with open(answer_file_val, \"r\") as f:\n",
        "    answer = json.load(f)\n",
        "    \n",
        "answer_image_pair_val = collections.defaultdict(list)\n",
        "for item in answer['annotations']:\n",
        "    ri = random.randint(0, 9)\n",
        "    answer = f\"{item['answers'][ri]['answer']}\"\n",
        "    tokens = word_tokenize(answer)\n",
        "    tokens = [t.lower() for t in tokens if t not in '''!,.;?()-[]{};:'\"\\<>/@#$+%^&*_~''']\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    answer = \" \".join(tokens)\n",
        "    # image_path = IMG_PATH + 'COCO_train2014_' + '%012d.jpg' % (item['image_id'])\n",
        "    image_path = IMG_PATH_VAL + 'COCO_val2014_' + '%012d.jpg' % (item['image_id'])\n",
        "    answer_image_pair_val[image_path].append(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3YOZjpwleGl"
      },
      "outputs": [],
      "source": [
        "image_paths = list(answer_image_pair.keys())\n",
        "random.shuffle(image_paths)\n",
        "images_train = image_paths\n",
        "\n",
        "image_paths_val = list(answer_image_pair_val.keys())\n",
        "random.shuffle(image_paths_val)\n",
        "images_val = image_paths_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQf19c6vleGl",
        "outputId": "96da02d0-53de-4139-eeda-b4f99d9ddf7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "443757\n",
            "443757\n",
            "443757\n"
          ]
        }
      ],
      "source": [
        "question_train = []\n",
        "answer_train = []\n",
        "img_names =  []\n",
        "\n",
        "for image_path in images_train:\n",
        "    question_for_img = question_image_pair[image_path]\n",
        "    question_train.extend(question_for_img)\n",
        "    answer_for_img = answer_image_pair[image_path]\n",
        "    answer_train.extend(answer_for_img)\n",
        "    img_names.extend([image_path]*len(question_for_img))\n",
        "print(len(question_train))\n",
        "print(len(answer_train))\n",
        "print(len(img_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-svpv7g_leGl",
        "outputId": "f68f7cea-b270-4b33-d792-c70d53adfccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "214354\n",
            "214354\n",
            "214354\n"
          ]
        }
      ],
      "source": [
        "question_val = []\n",
        "answer_val = []\n",
        "img_names_val =  []\n",
        "\n",
        "for image_path in images_val:\n",
        "    question_for_img = question_image_pair_val[image_path]\n",
        "    question_val.extend(question_for_img)\n",
        "    answer_for_img = answer_image_pair_val[image_path]\n",
        "    answer_val.extend(answer_for_img)\n",
        "    img_names_val.extend([image_path]*len(question_for_img))\n",
        "print(len(question_val))\n",
        "print(len(answer_val))\n",
        "print(len(img_names_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ25RJcipymf",
        "outputId": "f8daad48-594e-493c-f19d-167578696d8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5499\n"
          ]
        }
      ],
      "source": [
        "from nltk.probability import FreqDist\n",
        "fdist = FreqDist(answer_train)\n",
        "most_5500 = fdist.most_common(5500)\n",
        "most_5500 = [item[0] for item in most_5500]\n",
        "most_5500 = [item for item in most_5500 if item not in ['', \" \"]]\n",
        "# most_3000_l = [item[0] for item in most_3000 if len(item[0].split())>1]\n",
        "# print(most_3000_l)\n",
        "print(len(most_5500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIuaz630leGm"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "for (question, answer, image) in zip(question_train, answer_train, img_names):\n",
        "    if answer not in most_5500:\n",
        "        question_train[i] = '<rev>'\n",
        "        answer_train[i] = '<rev>'\n",
        "        img_names[i] = '<rev>'\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zz3wHQqIleGm"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "for (question, answer, image) in zip(question_val, answer_val, img_names_val):\n",
        "    if  answer not in most_5500:\n",
        "        question_val[i] = '<rev>'\n",
        "        answer_val[i] = '<rev>'\n",
        "        img_names_val[i] = '<rev>'\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4oOdTEAleGm"
      },
      "outputs": [],
      "source": [
        "question_train = [q for q in question_train if q != '<rev>']\n",
        "answer_train = [q for q in answer_train if q != '<rev>']\n",
        "img_names = [q for q in img_names if q != '<rev>']\n",
        "\n",
        "question_val = [q for q in question_val if q != '<rev>']\n",
        "answer_val = [q for q in answer_val if q != '<rev>']\n",
        "img_names_val = [q for q in img_names_val if q != '<rev>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNqgu1f7leGm",
        "outputId": "76e99117-bff2-4b9c-e21b-87b716197238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "409769\n",
            "409769\n",
            "409769\n"
          ]
        }
      ],
      "source": [
        "print(len(question_train))\n",
        "print(len(answer_train))\n",
        "print(len(img_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZBDJMH4leGm",
        "outputId": "cae4f7b3-f8aa-454c-ec9a-9276582d829c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "195346\n",
            "195346\n",
            "195346\n"
          ]
        }
      ],
      "source": [
        "print(len(question_val))\n",
        "print(len(answer_val))\n",
        "print(len(img_names_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Te1nXmoleGm"
      },
      "outputs": [],
      "source": [
        "question_train_dataset = tf.data.Dataset.from_tensor_slices(question_train)\n",
        "answer_train_dataset = tf.data.Dataset.from_tensor_slices(answer_train)\n",
        "# mid_token_train_dataset = tf.data.Dataset.from_tensor_slices(mid_tokens_train)\n",
        "\n",
        "question_val_dataset = tf.data.Dataset.from_tensor_slices(question_val)\n",
        "answer_val_dataset = tf.data.Dataset.from_tensor_slices(answer_val)\n",
        "# mid_token_val_dataset = tf.data.Dataset.from_tensor_slices(mid_tokens_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj2NyZtFv3MJ",
        "outputId": "5f73cdad-6e31-4228-8fcb-a2c77ef045af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "on counter\n"
          ]
        }
      ],
      "source": [
        "print(most_5500[665])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkqkcxFAleGm"
      },
      "outputs": [],
      "source": [
        "ans_tokenizer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=None,\n",
        "    standardize=None,\n",
        "    ngrams = 3,\n",
        "    output_sequence_length=1\n",
        ")\n",
        "ans_tokenizer.set_vocabulary('/content/drive/MyDrive/tokn_vocab')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oarm7gS2leGm",
        "outputId": "5ce54da0-e0d6-4170-a4ad-1f501232b2cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "question_embedding = question_train_dataset.map(lambda x: x)\n",
        "answer_embedding = answer_train_dataset.map(lambda x: ans_tokenizer(x))\n",
        "\n",
        "question_embedding_val = question_val_dataset.map(lambda x: x)\n",
        "answer_embedding_val = answer_val_dataset.map(lambda x: ans_tokenizer(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUb7zS85ct0p",
        "outputId": "3b098b59-68c2-412a-e9c1-214d352d58d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5501"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(ans_tokenizer.get_vocabulary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbtDlXRaleGm"
      },
      "outputs": [],
      "source": [
        "word_to_index = tf.keras.layers.StringLookup(\n",
        "    mask_token=\"\",\n",
        "    vocabulary=ans_tokenizer.get_vocabulary())\n",
        "index_to_word = tf.keras.layers.StringLookup(\n",
        "    mask_token=\"\",\n",
        "    vocabulary=ans_tokenizer.get_vocabulary(),\n",
        "    invert=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHpRyuPS1c1f",
        "outputId": "9c7a968f-c462-4d27-a7a5-bf12642b7204"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=9>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_to_index('black')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylsssLafOoZq",
        "outputId": "205e3084-b1e7-4112-990f-0a4a8e604bd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.1-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.1 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "d205866ac64a4d93ac5d5a16d9270ea9",
            "4b5bb5b8265a41e4bd1a5e869a286176",
            "add6c8dd4ce04fbba90019f72f9f5037",
            "9b7f8d7dd2a34b79a5427f99fba6c86b",
            "2459126d4ba14747bfa8d15e7bf02ec2",
            "96fb879896d34a0cb7dc529a6d50bd39",
            "8066ffebf5aa4e3fa470ff727bc6cb6c",
            "8f764131eed840c79a27849af3b54835",
            "9bdc45d06fa2459b9a996d72798d09c8",
            "4e6e89fd223a4571915ca8c303294fd8",
            "d0b86d98974946cb8e74f2e731154122"
          ]
        },
        "id": "VaCi4e12leGn",
        "outputId": "ce5f96c7-1d0c-4548-a519-9589595ecbcc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d205866ac64a4d93ac5d5a16d9270ea9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/352M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFViTModel.\n",
            "\n",
            "All the layers of TFViTModel were initialized from the model checkpoint at google/vit-base-patch32-224-in21k.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoImageProcessor, TFViTModel\n",
        "import torch\n",
        "\n",
        "def load_image(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.io.decode_jpeg(img, channels=3)\n",
        "    img = tf.keras.layers.Resizing(224, 224)(img)\n",
        "    img = img/255\n",
        "    img = tf.transpose(img)\n",
        "    return img\n",
        "\n",
        "image_train_dataset = tf.data.Dataset.from_tensor_slices(img_names)\n",
        "image_train_dataset = image_train_dataset.map(load_image)\n",
        "\n",
        "\n",
        "image_val_dataset = tf.data.Dataset.from_tensor_slices(img_names_val)\n",
        "image_val_dataset = image_val_dataset.map(load_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xlqb7lxwleGn"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 128\n",
        "train_dataset = tf.data.Dataset.zip((image_train_dataset, question_embedding))\n",
        "train_dataset = tf.data.Dataset.zip((train_dataset, answer_embedding))\n",
        "train_batches = train_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.zip((image_val_dataset, question_embedding_val))\n",
        "val_dataset = tf.data.Dataset.zip((val_dataset, answer_embedding_val))\n",
        "val_batches = val_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yip7_o1j99bn",
        "outputId": "e9290af1-704c-463c-d53c-cbe3b48721c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.1/630.1 KB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "pip install -q tf-models-official==2.11.0\n",
        "pip install tensorflow_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vit Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch32-224-in21k\")\n",
        "vit_model = TFViTModel.from_pretrained(\"google/vit-base-patch32-224-in21k\")\n",
        "vit_model.trainable = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BERT Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcSZ_PTSTBfF"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization\n",
        "preprocessing_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\", name='preprocessing')\n",
        "encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\", trainable=True, name='BERT_encoder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUDvxAw2leGn",
        "outputId": "912f2b83-4f5e-4f34-edca-3a52e8312e70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 1, 5695)\n"
          ]
        }
      ],
      "source": [
        "from model import QAModel\n",
        "for (image, question), label in train_batches:\n",
        "    break\n",
        "sample_model = QAModel(vit_model=vit_model, bert_encoder=encoder)\n",
        "sample_out = sample_model((image, question))\n",
        "print(sample_out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWiX6ZcXZOac"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "steps_per_epoch = tf.data.experimental.cardinality(train_batches).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 3e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DgUCU0sU8gf"
      },
      "outputs": [],
      "source": [
        "# Include the epoch in the file name (uses `str.format`)\n",
        "checkpoint_path = \"drive/MyDrive/Large_vocab_Epoch{epoch:04d}/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights every 5 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_freq=int(steps_per_epoch))\n",
        "\n",
        "# Create a new model instance\n",
        "model = QAModel(vit_model=vit_model)\n",
        "model.load_weights('/content/drive/MyDrive/Large_vocab_Epoch0002/cp-0002.ckpt')\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), optimizer=optimizer, metrics=['accuracy'])\n",
        "# # Save the weights using the `checkpoint_path` format\n",
        "model.save_weights(checkpoint_path.format(epoch=0))\n",
        "\n",
        "# Train the model with the new callback\n",
        "model.fit(train_batches, epochs=30,\n",
        "          callbacks=[cp_callback],\n",
        "          validation_data=val_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvVqd02uleGo",
        "outputId": "852cccb4-93ec-49fa-b3e1-86a5172258ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1527/1527 [==============================] - 835s 535ms/step - loss: 2.0407 - accuracy: 0.4458\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.040680170059204, 0.44579872488975525]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(val_batches)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.10.8 ('simvlm')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6de52dce80c3226d28e1cb258147f244f155ae69bf9dea3d4ab87b9aa038f5fe"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2459126d4ba14747bfa8d15e7bf02ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b5bb5b8265a41e4bd1a5e869a286176": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96fb879896d34a0cb7dc529a6d50bd39",
            "placeholder": "​",
            "style": "IPY_MODEL_8066ffebf5aa4e3fa470ff727bc6cb6c",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "4e6e89fd223a4571915ca8c303294fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8066ffebf5aa4e3fa470ff727bc6cb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f764131eed840c79a27849af3b54835": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96fb879896d34a0cb7dc529a6d50bd39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b7f8d7dd2a34b79a5427f99fba6c86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e6e89fd223a4571915ca8c303294fd8",
            "placeholder": "​",
            "style": "IPY_MODEL_d0b86d98974946cb8e74f2e731154122",
            "value": " 352M/352M [00:01&lt;00:00, 206MB/s]"
          }
        },
        "9bdc45d06fa2459b9a996d72798d09c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "add6c8dd4ce04fbba90019f72f9f5037": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f764131eed840c79a27849af3b54835",
            "max": 352450080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9bdc45d06fa2459b9a996d72798d09c8",
            "value": 352450080
          }
        },
        "d0b86d98974946cb8e74f2e731154122": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d205866ac64a4d93ac5d5a16d9270ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b5bb5b8265a41e4bd1a5e869a286176",
              "IPY_MODEL_add6c8dd4ce04fbba90019f72f9f5037",
              "IPY_MODEL_9b7f8d7dd2a34b79a5427f99fba6c86b"
            ],
            "layout": "IPY_MODEL_2459126d4ba14747bfa8d15e7bf02ec2"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
